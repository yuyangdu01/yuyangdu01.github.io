---
permalink: /research/
title: ""
author_profile: true
redirect_from: 
  - /md/
  - /markdown.html
---

<div align="center">
  <img src="../images/research01.jpg" width="30%">
  <img src="../images/research02.png" width="30%">
  <img src="../images/research03.png" width="30%">
</div>
<div align="center">
  <table style="border:none; border-collapse: collapse;">
    <tr>
      <td style="border:none; padding: 10px;" width="30%" align="center">Efficient AIs at Edge</td>
      <td style="border:none; padding: 10px;" width="30%" align="center">Highly Reliable Wireless Communications at Edge</td>
      <td style="border:none; padding: 10px;" width="30%" align="center">AI-Wireless Integration for Mobile Edge Applications</td>
    </tr>
  </table>
</div>
<br>


<div style="text-align: left;">
<details>
  <summary>
    <span style="text-align: center; font-size: 24px; font-weight: bold;">Efficient AIs at Edge</span>
  </summary>
  <br>

  <p style="text-align: justify;">A core challenge for intelligent mobile systems lies in the inherent conflict between the growing user demand for powerful AIs and the severe resource constraints at the edge. To address this, my recent works design and implement cost-effective LLM agents for edge scenarios. I use LLM post-training techniques (e.g., supervised fine-tuning, knowledge distillation, and model alignment) to boost the performance of lightweight models for specific edge applications. I am also actively exploring distributed LLM inference powered by MoE architecture. My research enables the aggregation of fragmented and underutilized computational resources across massive distributed IoT devices for supporting large-scale LLMs at the edge.
  </p>
  <p>Selected Publications:</p>
  <span style="font-size: 12px; color: grey;">(underlines for student co-advised, * for equal contribution, # for corresponding author/project lead)</span>
  <br>

  <p style="font-size: 18px; font-weight: bold;">Application-Specific Agents:</p>

  
</details>
</div>
